Sns등 특정 크롤을 + 강화학습 기반으로 할 수 있도록
재혁님은 조사 테스트 위주
기홍님 개발 위주

두분 잘 논의하셔서 ppt 1~5장 정도로 계획 짜 보세요

#### 스크래핑 사이트
SNS: 레딧 (시간 되면 인스타 추가(그런데 봇에 민감함))
웹: 구글
미디어 플랫폼: 유튜브(시간 되면 틱톡, 넷플릭스 추가)

#### 모델들
기사냐 아니냐를 판단하는 모델
1. BitNet b1.58 2B4T
2. Llama3-8B-1.58

벡터 DB 를 공부 해봤는데
LLM에 질문을 던지면 벡터 DB를 서치를 한다.
제가 크롤링한 내용들이 
이미지, 동영상, 기사 
DB 에 넣으면 embedding 이라고 하는데 벡터공간 값을 만들어서 벡터 DB가 찾는거다. 유사도를 (코사인 유사도 같은 것을 이용해서) 즉, LLM은 동영상, 이미지, 기사 를 직접 classify 하는게 아니라 질문만 던지는 역할을 할 것이다.
Embedding 모델이 있는데 거기에 이미지나 동영상 넣으면 벡터값으로 변환해주는데, 벡터DB가 유사도를 계산해서 질문에 맞는 
그거를 이제 벡터DB를 사용해야 하는 것 같다.

기사냐 이미지냐 동영상이냐 까지는 분류할 필요가 없을거 같고, 

Reddit 에서 예를 들어서 링크 하나 스크래핑 한다고 하면
거기 기사 내용도 들어올거고
동영상도 들어올건데 이거는 동영상인 부분을 찾아서 yt-dlp 라는 파이썬 툴이 있어요, 그걸로 받아올거라 동영상이냐 기사냐는 이 단계에서 분류가 될 거 같거든요

동영상 아까 예제처럼 10개 프레임만 갖다 쓰는식으로 할 거 같고

기사냐 아니냐 <- 이거는 스크래핑 단계에서 처리할 수도 있을거 같은데 굳이 LLM 안쓰고
광고냐 아니냐 정도는 판단해야 할거 같기는 해요

Q. 기사냐 아니냐 판단하는데 LLM 안 쓰고 스크래핑이나 크롤링에서 끝날거 같은데 왜 LLM 써야하는가? 그런데 LLM으로 판단해야 한다면 기사 긁어주고 판단해줘 라고 해야할거 같고, 그리고 기사인지 아닌지 판단해서 그 다음에 DB에 넣으라는건가?

Q. bitnet 에 이미지를 비트맵을 인식하게 한다 = 학습을 시켜야 한는것인가? 멀티 모달로 프롬프트에 토큰 형식으로 전달해야 하는것인가? 이미지를 분류가 가능해질 경우, 동영상도 bitnet 에 프레임을 전달하여서 구분해야 되는 부분인가, ... bitnet 에 이미지 프레임을 학습시키는 것 보다는 그냥 벡터DB 이용해서 분류 search 하게 하는게 더 낫지 않나?

이거를 모델한테 해도 되는데 사이트 구조가 안 바뀐다면 스크래핑/크롤링 단계에서도 기사 분류 가능한데, 선생님이 원하시는건 어느 사이트건 떼거지로 가져오거나, 아니면 해당 사이트가 변경되더라도 계속 동작하게끔 하기 위해서 LLM 을 써라 라면 이해가 가는데

---
- 백엔드에서 클라이언트가 하는일이 뭐더라



영상 생성, 음성 생성, 스토리 생성
세개 이것 저것 돌려보면서 적합한거 찾아주세요

나는 데이터 모을 준비를 해야한다. 타겟으로 했던 레딧이나 기존의 메타나 엑스나 그 중의 하나라도 골라서 거기에 원하는 타입, 예를 들어 경제면 경제 타겟 일단 하나 해서 벡터 디비 크로마 사용하면 될거고 벡터디비에 넣으면 되고
경제랑 관련이 있다는걸 판단할 때 재혁님이 그 모델 하나를 더해주세요 그럼 네개겠네요. 4개를 넣으면 멀티모달로 되어있는 데이터 어떤 분류인지 경제 기사인지, 일반 소셜인지 그런걸 확인할 수 있게 해주면 일단은 될 것 같아요

이것만 해도 한 달 걸릴듯

Red - "CPU 환경에서 모델 돌리기로 했는데, CPU에 적합한 라마나 비트넷을 말씀 주셨고 그러면 이게 지금 기홍님이 스크래핑을 하면 스크래핑 한걸 동영상을 벡터화시키고 이미지를 비트넷으로 변환을 시킨다면 그거를 LLM에 넣어서 분류를 해서 DB에 저장한다고 해야하나? 재혁님이 클리어하게 해줘야 한다. 이 LLM이 임베딩이 된 데이터로 들어갔을 때 정상적으로 얘가 인식할 수 있는지 먼저 확인을 해 줘야 한다. 흐름은 스크래핑 한걸 임베딩화 시키고 임베딩한걸 LLM에 넣는다고 이해하면 되나?"

이 방법도 찾아내야 한다. 텍스트 어떻게 임베딩 해서 넣을건지 사진 어떻게 임베딩해서 넣을건지 그래서 재혁님이 아까 말한 4번째 그렇게 멀티모달 형태의 데이터가 들어갔을 때 적절하게 잘 분류하는지 그 모델을 찾아줘야 한다. 멀티모달로 학습할 자원이 안될걸. 학습을 보는게 아니라 재혁님은 영상생성 모델 괜찮은걸 찾고, 음성생성 모델을 찾고, 텍스트 생성 모델인데 스토리를 잘 짜는거. 그리고 네번째가 기홍님이 끌어온 기사들이 어떤 타입 경제, .... 확인해줄 수 있는 멀티모달 형태가 들어갔을 때 확인해줄 수 있는 모델. (이게 LLM 인가? 사실상 LLM 에 가까운데 LLM에 제한을 두고 찾을 필요는 없다. 사진이 있는 기사라고 했을 때 사진을 요약해줘 + 기사 내용을 넣어서 그거를 또 분류해줘 이런식으로 프롬프트를 짤 수 있다. 기사만? 영상만? A. 다 포함이 되는게 BEST. 4번으로 전달할 때는 기홍님이랑 조율해야 한다는 말인가? A. 맞습니다. 조율 해야 합니다. 크롤 해서 확장자로 영상이라던가 하는게 재혁님 모델로 가겠죠. 확장자를 이용하는 방법도 있고. 둘 다 쿠버네티스 기반에서 만드는 것 잊지 말구요. 둘 다 각자 API서버가 있어야 한다. 모델 하나하나가 다 다른 서버에 있는거 잊지 말아라.) 사진내용 요약 이랑 기사내용을 합친 내용으로 분류를 할 수 있다는 말. 기사만 있으면 기사 내용으로만 요약하던가 하면 되고.

스토리 생성은 어디에 쓰냐 : 스토리대로 영상이 생성이 되고 음성이 만들어질겁니다. 스토리 별거 없어요 그냥 GPT 써도 되요. 

1,2,3,4 네개 모델이 필요했죠. 어떤거는 1, 2가 합쳐진게 있다. 그러면 그 모델로 1, 2번 처리하면 되고

기홍님 쪽에서 모델 하나 또 건드려야 하는데, 크롤 하다가 기사 있잖아요 텍스트 사진 기사 이런건 적절하게 분류해서 넣으면 되는거고 그게 4번 모델인거고. 기홍님만의 신경써야되는걸 그냥 랜덤하게 돌아다녀요. 유튜브든 어디든 그리고 동영상이든 기사든 상관이 없어요. 그게 적절하게 잘 요약이 되는 요약을 찾아야됩니다. 그거 학습시키는거 아니에요. 검색해서 적절하게 실행하면 되는거에요.

기홍님이 최근 트렌드를 그 모델이 모아와줄건데, 최근 트렌드들 뽑아줄건데 그 출력을 가지고 영상, 음성 모델에 생성이 되서 나오면. 

제 모델은 트렌드를 생성하라고 했는데 크롤러가 어디든 랜덤하게 돌아다니면 되요. 주기는 그냥 1달이든 1주일단위든 기준 정해서 하시고, 그게 나중에 DB에 저장이 될 거잖아요. 저장되어있는걸 재혁님에게 찾으면 됩니다. 저장할때 그래프DB사용해도 되고, 그래프 DB 사용할 때 관계가 필요할 때 ex 기사1 (오늘의 주가) 기사2 어제의 주가 그런데 또 다른 기사는 오늘의 산업 어제의 주가와 어제의 산업이 뭐 연결될 수도 있을 거고 그래프 DB를 사용할거면 대략 그렇게. 그 기사를 어떻게 벡터DB에다가 기사 하나를 벡터화시키는 값은 아마 찾으면 되요. 시중에 나와있는거 있을거고. 필요할 때 바로 서치해서 사용할 수 있겠네요. 그리고 RDB에 전체를 하나 모아두세요. 몽고보다는 RDB가 더 빠르긴 하다. 전체 다 RDB에 최대한 쌓아두고 필요한 부분만 그래프, 벡터, 몽고DB에 뽑아서 해놓으면 되겠죠. 크로마도 있고 서치도 있고 한데 오픈소스중에 chroma 도 있는데 chroma 사용하면 어떨지 모르겠고 공부하는 책에서는 chroma 썼다. 그러면 차라리 chroma 로 해라. 

분류하는건 멀티모달 하는건 기홍님쪽 그렇게 총 5개. 재혁님은 4개 아까 멀티모달이 들어올 때 

API 서버 쓰기 편한거 쿠버네티스 위에 하나 만들어놓으면 1번 모델 경로 넣어주고 API 구조만 조금 바꾸면 되잖아요 2번 모델은 2번 모델에 경로 넣어주고 URL API 경로만 넣어주고. 그렇게 해서. 자바 백엔드는 나중에 하고 백엔드 에서 API 던질건데, 자바 백엔드에서 라우팅을 할래요, 아니면 라우팅 API 를 만들어서 할래요?(자바 백엔드가 라우팅 API에 던지고, 라우팅 API가 모델1인게 여러개 뜰거에요 서버가. 그 중에 어느쪽으로 보낼지 경로를 결정해 주는거. 지난 회의 때 일단 뭐 다 얘기는 했는데 한번 더 들으면 기억은 날거에요) 지금은 일단 라우팅 서버 하나, 그리고 각각 모델에 올라가는 서버들

무료 한정으로 API면 할만한데 거기도 제약사항이 있다. 이왕이면 오픈소스 모델을 찾아야해요. 

그러면 일요일정도쯤 해서 그냥 어딘가 제출할거 아니니까 기홍님 재혁님 합쳐서 나오는 전체 구조 하나랑 메모에 화살표만 있으면 된다. 그거 하나랑, 재혁님이 계획한 일정. 뭐 1번 모델은 세부내용 디테일 안해도 되요. 생각 나는데 까지만. 모델 1번의 세부내용은 이거고 모델1번의 전체 완성 찾는게 걸리는 시간, 기홍님은 라우팅서버 만드는데 걸리는 시간 각자 한장이랑 합쳐서 나오는 1장. 그렇게만 가지고 일요일에 얘기 해보죠.

쿠버네티스 책을 줄게요. 그 공부도 같이 하면서 찾는것도 같이 해야해요. 그 다음에 일요일날 적절한 시간에 혜성쌤한테 얘기를 주세요.

\+ 현대차에 로봇타러 갈사람 있나요? 자동차 로봇 만드는 현대차 울산 공장에 환경 같은거 어떻게 되있는지 할 여유있는 사람 있나요? 주말이면 재혁님 가능한데. 주말이면 공장이 쉬어서 안되요. 얘기는 해봐야되는데, 주말에 가는거는 혜성쌤이랑 갈거고. 주말에 재혁님 기홍님 같이 가고, 평일에 가야될때는 기홍님 혼자서 조금 처리해요. 가서 기존의 설치되어있는 정보를 빼내오고, 서울에 있는 업체가 만드는데 2년 걸렸대요. 어떤 기종인지 정보를 빼오라. 제작 하면 그걸 가져와서 설치하고 내부에서 프로그램 만지면서 캘리브레이션이라는걸 해야해요. 그 공장에서 적합하게 해주는 작업. 그런거 등등을. 어떤 기종을 쓰는지 물어보면 안 알려준다. 뜯어보고 메인보드에 적혀있는거 보고 데이터시트 찾고. 울산차에 로봇 넣는 업체가 있고, 그 밑에 하청으로 들어간 업체가 있다. 로봇 넣는 업체에 아는 사람 있어서 그권한은 아마 줘요. 80% 줍니다. 몰래몰래 빼내갈 수 있도록. 이거를 평일에 가는거다. 바로 수익을 얻을 수 있어요. 그걸로 고생한 만큼 수익을 분배를 할거니까. 실력도 쌓을 수 있고, 제가 볼 때는 이런 기회가 없어요.

기한: 빠르면 10월부터 시작이 될 수도 있어요. 10월 말. 11월에 재혁님 복귀하는데. 둘 다 가는게 사실 좋아요 경험 쌓는게. 매주 가야되는게 뭐 초반일거고. 중간에 그런 정보 가져오고 제가 설계하고 완성이 되면 거기에 납품하러 가야겠죠. 그 때쯤에는 또 자주 가야할가고. 그러면 혜성샘이 설계하다가 이 정보가 필요하네 하면 또 현대차공장 가야하고. 이거는 한 대 넣을 때 2억정도 나오거든요. 개발 한 번 할 때 사실 몇억 들어가죠. 그런데 이게 10대만 들어가도 우리가 충분히 먹고 살아요. 그런데 한 번 잡아놓으면 현대차공장만 잡아놓으면 다른데 다 넣을 수 있거든요 경남 대구 전체. 그러면 향후 5년 10년은 뭐 걱정 없어요. 

캐시카우가 없으면 한국에서는 위한테 너무 흔들려야해요. 캐시카우만 되면 월500은 벌어들입니다. 

사무실은 이사님쪽에서 알아보실거고 사무실은 무조건 대구에요. 로봇은 무조건 대구. 캐시카우는 어디로 할지는 제가 사무실은 하나 있어요. 경기도쪽에 하나 있어서. 뭐 거기로 할지 아니면 그냥 가까운 서울에 임대를 놓을지.

광주에 계속 있을건지? 광주에 신축이 들어섰어요. 거기에 하겠다하면 캐시카우를 거기에 거점에 잡아버리는게 좋을 수도 있고. 

대구에 사무실 놓았을 때 장점: 중소기업들이 엄청 많아요. 대구시는 로봇 특화거든요. 
대구 광주 왔다갔다하는게 제일 좋아요. 서울쪽도 괜찮은데 서울은 기관잡기가 쉽지 않아요. 고인물이 너무 많아서. 대구 광주 놓고 바로 미국으로 가는게 제일 좋아요. 영어는 유튜브에 회화공부치면 짧막한거 500개씩 나오는게 있는데 들어만 놔라 이해하지 말고. 나중에 자연스럽게 이해하게 된다.