───────────────────────────────────────────────
                    Transformer
───────────────────────────────────────────────
│
│  ┌─────────────────────────────────────────┐
│  │              ENCODER STACK              │
│  │  (N layers, 예: 6개 블록 반복)          │
│  │─────────────────────────────────────────│
│  │  Input Embedding                        │
│  │       ↓                                 │
│  │  Positional Encoding                    │
│  │       ↓                                 │
│  │  ┌───────────────────────────────────┐  │
│  │  │ Multi-Head Self-Attention         │  │
│  │  │   Q,K,V 생성 → QKᵀ/√d → Softmax  │  │
│  │  │   → Weighted Sum (V)              │  │
│  │  └───────────────────────────────────┘  │
│  │       ↓                                 │
│  │  Add & LayerNorm                       │
│  │       ↓                                 │
│  │  Feed Forward Network (with GELU)      │
│  │       ↓                                 │
│  │  Add & LayerNorm                       │
│  │─────────────────────────────────────────│
│  │  ↑ 위 블록을 N번 반복 ↑                │
│  └─────────────────────────────────────────┘
│
│
│  ┌─────────────────────────────────────────┐
│  │              DECODER STACK              │
│  │─────────────────────────────────────────│
│  │  Output Embedding                       │
│  │       ↓                                 │
│  │  Positional Encoding                    │
│  │       ↓                                 │
│  │  ┌───────────────────────────────────┐  │
│  │  │ Masked Multi-Head Self-Attention  │  │
│  │  └───────────────────────────────────┘  │
│  │       ↓                                 │
│  │  Add & LayerNorm                       │
│  │       ↓                                 │
│  │  ┌───────────────────────────────────┐  │
│  │  │ Encoder–Decoder Cross-Attention   │  │
│  │  │  (Decoder Query + Encoder Key/Val)│  │
│  │  └───────────────────────────────────┘  │
│  │       ↓                                 │
│  │  Add & LayerNorm                       │
│  │       ↓                                 │
│  │  Feed Forward Network (with GELU)      │
│  │       ↓                                 │
│  │  Add & LayerNorm                       │
│  │─────────────────────────────────────────│
│  │  ↑ 위 블록을 N번 반복 ↑                │
│  └─────────────────────────────────────────┘
│
│
│  ┌─────────────────────────────────────────┐
│  │           Linear + Softmax              │
│  │    → 확률 분포로 최종 출력 생성         │
│  └─────────────────────────────────────────┘
│
───────────────────────────────────────────────