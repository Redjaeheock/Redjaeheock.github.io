
[위키백과](https://ko.wikipedia.org/wiki/%EC%8A%A4%ED%85%8C%EC%9D%B4%EB%B8%94_%EB%94%94%ED%93%A8%EC%A0%84)
# Stable Diffusion

- 2022년 출시된 딥러닝
- 스타트업 스태빌리티 AI(Stability AI)가 여러 학술 연구원 및 비영리 단체와 공동으로 개발
- 텍스트-이미지 모델
	- **텍스트 설명에 따라 상세한 이미지를 생성**하는 데 주로 사용되지만 
	  인페인팅, 아웃페인팅, 이미지 생성과 같은 다른 작업에도 적용할 수 있다
- 심층 생성 신경망의 일종인 **잠재 확산 모델**
- 코드 및 모델 가중치가 공개되었으며 최소 8GB VRAM이 있는 일반 GPU가 장착된 대부분의 
  **소비자 하드웨어에서 실행할 수 있다**
	- 클라우드 서비스를 통해서만 액세스할 수 있었던 [DALL-E](https://ko.wikipedia.org/wiki/DALL-E "DALL-E") 및 [Midjourney](https://ko.wikipedia.org/wiki/Midjourney "Midjourney")와 같은 
	  이전의 **독점 텍스트-이미지 모델에서 출발**했다
- 아키텍처
	- 스테이블 디퓨전은 LMU 뮌헨의 CompVis 그룹에서 개발한 **LDM**(잠재 확산 모델)이라는 일종의 확산 모델(DM)을 사용한다. 
	- 2015년에 도입된 확산 모델은 훈련 이미지에서 가우스 잡음의 연속 적용을 제거하는 목적으로 훈련
		-  이는 일련의 노이즈 제거 자동 인코더로 생각할 수 있다
	- 스테이블 디퓨전은 **VAE**(Variational Autoencoder), **U-Net** 및 **선택적 텍스트 인코더**의 
	  세 부분으로 구성
	- VAE 인코더
		- 이미지를 픽셀 공간에서 더 작은 차원의 잠재 공간으로 압축하여 이미지의 보다 근본적인 의미를 포착
		- 가우스 노이즈는 순방향 확산 중에 압축된 잠재 표현에 반복적으로 적용
	- U-Net
		- ResNet 백본
		- 순방향 확산의 출력을 역방향으로 제거하여 잠재 표현을 얻는다
	- VAE 디코더
		- 표현을 다시 픽셀 공간으로 변환하여 최종 이미지를 생성
	- 잡음 제거 단계
		- 텍스트 문자열, 이미지 또는 다른 형식에 따라 유연하게 조절될 수 있다 
		- 인코딩된 조건 데이터는 교차 주의 메커니즘을 통해 노이즈 제거 U-Net에 노출된다.
		-  텍스트 조건을 지정하기 위해 사전 훈련된 고정 CLIP ViT-L/14 텍스트 인코더를 사용하여 텍스트 프롬프트를 임베딩 공간으로 변환한다연구원들은 LDM의 장점으로 훈련 및 생성을 위한 계산 효율성 향상을 지적한다.
- 제한사항
	- 안정 확산에는 특정 시나리오에서 성능 저하 및 부정확성 문제가 있다
		- 모델의 초기 릴리스는 512×512 해상도 이미지로 구성된 데이터 세트에서 훈련했기때문에 사용자 사양이 "예상" 512×512 해상도에서 벗어날 때 생성된 이미지의 품질이 눈에 띄게 저하된다
		- 스테이블 디퓨전 모델의 버전 2.0 업데이트
			- 768×768 해상도의 이미지를 기본적으로 생성하는 기능이 도입
		-  LAION 데이터베이스의 팔다리 데이터 품질이 좋지 않아 인간 팔다리를 생성하는 것
			-  데이터베이스에 대표적인 특징이 부족하여 모델이 사람의 팔다리와 얼굴을 이해하도록 충분히 훈련되지 않았으며 모델이 이러한 유형의 이미지를 생성하도록 유도하면 모델이 혼란스러울 수 있다
			- 스테이블 디퓨전 XL(SDXL) 버전 1.0
				- 기본 1024x1024 해상도를 도입하고 팔다리 및 텍스트 생성을 개선
- 최종 사용자 미세 조정
	- 모델의 초기 훈련의 한계를 해결하기 위해 최종 사용자는 보다 구체적인 사용 사례에 
	  맞게 생성 출력을 미세 조정하기 위한 추가 훈련을 구현하도록 선택할 수 있다
	- 이 프로세스는 개인화라고도 한다. 사용자가 접근할 수 있는 미세 조정을 
	  스테이블 디퓨전 모델 체크포인트에 적용할 수 있는 세 가지 방법이 있다.